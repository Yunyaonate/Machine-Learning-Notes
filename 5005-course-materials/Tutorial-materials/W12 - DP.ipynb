{"cells":[{"cell_type":"markdown","metadata":{"id":"WE31MCP8FDjz"},"source":["\n","## Implementing Differential Privacy SGD (DP-SGD) with Opacus\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Hn2dbZi4oDlO"},"source":["### Library Installation and Dataset Preparation"]},{"cell_type":"markdown","metadata":{"id":"C4LFRSd8IrHB"},"source":["First, let's install the Opacus. Opacus is a library that enables training PyTorch models with differential privacy."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3595,"status":"ok","timestamp":1666067437520,"user":{"displayName":"Daochang Liu","userId":"09676986799738035755"},"user_tz":-660},"id":"3WgrHq13zr2R","outputId":"11c2ecb8-cf10-4057-b7a1-271b49662cdf"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: opacus in /usr/local/lib/python3.7/dist-packages (1.2.0)\n","Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.21.6)\n","Requirement already satisfied: scipy>=1.2 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.7.3)\n","Requirement already satisfied: functorch in /usr/local/lib/python3.7/dist-packages (from opacus) (0.2.1)\n","Requirement already satisfied: opt-einsum>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from opacus) (3.3.0)\n","Requirement already satisfied: torch>=1.8 in /usr/local/lib/python3.7/dist-packages (from opacus) (1.12.1+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.8->opacus) (4.1.1)\n"]}],"source":["# install opacus [https://github.com/pytorch/opacus]\n","!pip install opacus"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","height":260},"executionInfo":{"elapsed":5340,"status":"ok","timestamp":1666067442853,"user":{"displayName":"Daochang Liu","userId":"09676986799738035755"},"user_tz":-660},"id":"Ag9LeXEyoZlF","outputId":"2ee1b0c3-851c-439f-c6f7-3d71a4794586"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-1c481cfc-7dea-47f9-8b74-4729b4869374\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>UnderwaterDensity</th>\n","      <th>BodyFatSiriEqu</th>\n","      <th>Age</th>\n","      <th>Height</th>\n","      <th>Weight(kg)</th>\n","      <th>NeckCircumf</th>\n","      <th>ChestCircumf</th>\n","      <th>Abdomen2Circumf</th>\n","      <th>HipCircumf</th>\n","      <th>ThighCircumf</th>\n","      <th>KneeCircumf</th>\n","      <th>AnkleCircumf</th>\n","      <th>ExtendBicepsCircumf</th>\n","      <th>ForearmCircumf</th>\n","      <th>WristCircumf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1.0708</td>\n","      <td>12.3</td>\n","      <td>23</td>\n","      <td>172.085</td>\n","      <td>69.96662</td>\n","      <td>36.2</td>\n","      <td>93.1</td>\n","      <td>85.2</td>\n","      <td>94.5</td>\n","      <td>59.0</td>\n","      <td>37.3</td>\n","      <td>21.9</td>\n","      <td>32.0</td>\n","      <td>27.4</td>\n","      <td>17.1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0853</td>\n","      <td>6.1</td>\n","      <td>22</td>\n","      <td>183.515</td>\n","      <td>78.58488</td>\n","      <td>38.5</td>\n","      <td>93.6</td>\n","      <td>83.0</td>\n","      <td>98.7</td>\n","      <td>58.7</td>\n","      <td>37.3</td>\n","      <td>23.4</td>\n","      <td>30.5</td>\n","      <td>28.9</td>\n","      <td>18.2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.0414</td>\n","      <td>25.3</td>\n","      <td>22</td>\n","      <td>168.275</td>\n","      <td>69.85322</td>\n","      <td>34.0</td>\n","      <td>95.8</td>\n","      <td>87.9</td>\n","      <td>99.2</td>\n","      <td>59.6</td>\n","      <td>38.9</td>\n","      <td>24.0</td>\n","      <td>28.8</td>\n","      <td>25.2</td>\n","      <td>16.6</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.0751</td>\n","      <td>10.4</td>\n","      <td>26</td>\n","      <td>183.515</td>\n","      <td>83.80119</td>\n","      <td>37.4</td>\n","      <td>101.8</td>\n","      <td>86.4</td>\n","      <td>101.2</td>\n","      <td>60.1</td>\n","      <td>37.3</td>\n","      <td>22.8</td>\n","      <td>32.4</td>\n","      <td>29.4</td>\n","      <td>18.2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.0340</td>\n","      <td>28.7</td>\n","      <td>24</td>\n","      <td>180.975</td>\n","      <td>83.57439</td>\n","      <td>34.4</td>\n","      <td>97.3</td>\n","      <td>100.0</td>\n","      <td>101.9</td>\n","      <td>63.2</td>\n","      <td>42.2</td>\n","      <td>24.0</td>\n","      <td>32.2</td>\n","      <td>27.7</td>\n","      <td>17.7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c481cfc-7dea-47f9-8b74-4729b4869374')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-1c481cfc-7dea-47f9-8b74-4729b4869374 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-1c481cfc-7dea-47f9-8b74-4729b4869374');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   UnderwaterDensity  BodyFatSiriEqu  Age   Height  Weight(kg)  NeckCircumf  \\\n","0             1.0708            12.3   23  172.085    69.96662         36.2   \n","1             1.0853             6.1   22  183.515    78.58488         38.5   \n","2             1.0414            25.3   22  168.275    69.85322         34.0   \n","3             1.0751            10.4   26  183.515    83.80119         37.4   \n","4             1.0340            28.7   24  180.975    83.57439         34.4   \n","\n","   ChestCircumf  Abdomen2Circumf  HipCircumf  ThighCircumf  KneeCircumf  \\\n","0          93.1             85.2        94.5          59.0         37.3   \n","1          93.6             83.0        98.7          58.7         37.3   \n","2          95.8             87.9        99.2          59.6         38.9   \n","3         101.8             86.4       101.2          60.1         37.3   \n","4          97.3            100.0       101.9          63.2         42.2   \n","\n","   AnkleCircumf  ExtendBicepsCircumf  ForearmCircumf  WristCircumf  \n","0          21.9                 32.0            27.4          17.1  \n","1          23.4                 30.5            28.9          18.2  \n","2          24.0                 28.8            25.2          16.6  \n","3          22.8                 32.4            29.4          18.2  \n","4          24.0                 32.2            27.7          17.7  "]},"execution_count":44,"metadata":{},"output_type":"execute_result"}],"source":["!pip install -U -q PyDrive\n","import os\n","import pandas as pd\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","# Authenticate and create the PyDrive client.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","if not os.path.exists('/content/BMI.csv'):\n","    link = '1_jBaXC32QcfGOHo2J5040PuEU7TAKj7Y'  # Restricted shared link\n","    downloaded = drive.CreateFile({'id':link}) \n","    downloaded.GetContentFile('BMI.csv')\n","\n","df = pd.read_csv('/content/BMI.csv')\n","\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"dso5x851sftY"},"source":["We treat the columns in the csv as features and perform classification task with BMI.\n","\n","There is no BMI data in this dataset, so we can calculate the BMI value following \n","$ BMI=\\frac{Weight(kg)}{Height(m)^2} $\n","\n","We now create our dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"qz0Wy8YU96dD"},"outputs":[],"source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","import torch\n","import numpy as np\n","from torch.utils.data import Dataset, Subset, DataLoader\n","from torchvision import datasets, transforms,models\n","import torch.optim as optim\n","import os\n","\n","class MyDataset(Dataset):\n"," \n","  def __init__(self,df, mean=None, std=None):\n","    # Get Height and Weight\n","    x = np.stack(df.iloc[:,:].values,axis=1).transpose()\n","    if mean is not None:\n","      self.mean = mean\n","      self.std = std\n","    else:\n","      self.mean = x.mean(axis=0, dtype=np.float32)\n","      self.std = x.std(axis=0, dtype=np.float32)\n","    # Define BMI\n","    df['BMI'] = df['Weight(kg)']/(df['Height']*df['Height']/10000)\n","    # Divide BMI into 4 categories\n","    df['BMI_category'] = \"not defined\"\n","    df['BMI_category_int'] = \"not defined\"\n","\n","    df['BMI_category'][df['BMI']<18.5] = \"Underweight\"\n","    df['BMI_category'][(df['BMI']>=18.5) & (df['BMI']<=24.99)] = \"Healthy Weight Range\"\n","    df['BMI_category'][(df['BMI']>=25) & (df['BMI']<=29.99)] = \"Overweight\"\n","    df['BMI_category'][df['BMI']>=30] = \"Obese\"\n","\n","    df['BMI_category_int'][df['BMI']<18.5] = 0\n","    df['BMI_category_int'][(df['BMI']>=18.5) & (df['BMI']<=24.99)] = 1\n","    df['BMI_category_int'][(df['BMI']>=25) & (df['BMI']<=29.99)] = 2\n","    df['BMI_category_int'][df['BMI']>=30] = 3\n","\n","    y = np.array(df['BMI_category_int'].values, dtype=int)\n","    x = torch.from_numpy(x)\n","    y = torch.from_numpy(y)\n","\n","    self.x=torch.tensor(x,dtype=torch.float32)\n","    self.y=torch.tensor(y,dtype=torch.int64)\n"," \n","  def mean_std(self):\n","    return self.mean, self.std\n","\n","  def __len__(self):\n","    return len(self.y)\n","   \n","  def __getitem__(self,idx):\n","    data = self.x[idx]\n","    target = self.y[idx]\n","    data = (data - self.mean) / self.std\n","    return data, target"]},{"cell_type":"markdown","metadata":{"id":"_mLM4bezsza4"},"source":["We split the csv into training set and testing set."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1666067442854,"user":{"displayName":"Daochang Liu","userId":"09676986799738035755"},"user_tz":-660},"id":"1OWLMCxxChi_","outputId":"bd5db080-5542-40d6-c524-9d884f37c4a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:27: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:8870: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  return self._update_inplace(result)\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:33: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:35: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]}],"source":["df = pd.read_csv('/content/BMI.csv')\n","df_size = df.shape[0]\n","split_ratio = 0.8\n","index = int(df_size*split_ratio)\n","train_df = df.iloc[0: index,:]\n","test_df = df.iloc[index:, :]\n","\n","trainset = MyDataset(train_df)\n","mean, std = trainset.mean_std()\n","testset = MyDataset(test_df, mean, std)"]},{"cell_type":"markdown","metadata":{"id":"F_iG1o5ppm0E"},"source":["### Build Toy Neural Network"]},{"cell_type":"markdown","metadata":{"id":"nYU8DTjjpgcy"},"source":["Opacus provides a good encapsulation of DP-SGD upon pre-defined models and optimizers. To utilize Opacus, we take a toy Neural Net as an example."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"6bsiQ3M8EJ4J"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class ToyNN(nn.Module):\n","    def __init__(self):\n","        super(ToyNN, self).__init__()\n","        self.fc1 = nn.Linear(15, 30)\n","        self.fc2 = nn.Linear(30, 8)\n","        self.fc3 = nn.Linear(8, 4)\n","        self.act = nn.Tanh()\n","        self.dropout = nn.Dropout(p=0.5)\n","\n","    def forward(self, x):\n","        x = self.fc1(x) # -> [B, 30]\n","        x = self.act(x) # -> [B, 30]\n","        x = self.dropout(x)\n","        x = self.fc2(x) # -> [B, 8]\n","        x = self.act(x) # -> [B, 8]\n","        x = self.dropout(x)\n","        x = self.fc3(x) # -> [B, 4]\n","        return x\n","\n","    def name(self):\n","        return \"ToyNN\""]},{"cell_type":"markdown","metadata":{"id":"TJP6jdE0tP8k"},"source":["We can simply wrap our toyNN and dataloader by the PrivacyEngine."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1666067443364,"user":{"displayName":"Daochang Liu","userId":"09676986799738035755"},"user_tz":-660},"id":"AyYw-0vktatu","outputId":"e0deabb7-4667-4892-ec6b-d284b415b586"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/opacus/privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n","  \"Secure RNG turned off. This is perfectly fine for experimentation as it allows \"\n"]}],"source":["from opacus import PrivacyEngine\n","\n","# set standard parameters\n","epochs = 50\n","lr = 1e-3\n","batchsize = 16\n","weight_decay = 5e-4\n","# set parameters for DP-SGD\n","noise_multiplier = 1.1\n","max_grad_norm = 1.0\n","delta = 1e-5\n","\n","# create data loaders\n","trainloader = DataLoader(trainset, batch_size=batchsize, shuffle=True, num_workers=1)\n","testloader = DataLoader(testset, batch_size=batchsize, shuffle=False, num_workers=1)\n","# define your components as usual\n","model = ToyNN()\n","# define optimizer and loss function\n","optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n","criterion = nn.CrossEntropyLoss()\n","# enter PrivacyEngine\n","privacy_engine = PrivacyEngine()\n","model, optimizer, trainloader = privacy_engine.make_private(\n","    module=model,\n","    optimizer=optimizer,\n","    data_loader=trainloader,\n","    noise_multiplier=noise_multiplier,\n","    max_grad_norm=max_grad_norm,\n",")"]},{"cell_type":"markdown","metadata":{"id":"odGhFdlCtvR8"},"source":["With returned model, optimizer, and trainloader, we can train our network with differential privacy. The $\\epsilon$ and $\\delta$ correspond to the ($\\epsilon$, $\\delta$)-DP in Lecture Slides."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"mpo0WvOhE0CB","outputId":"d29cdd56-0653-40ff-de6e-f5976ff6bcc6"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n","  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:729: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n","  \"please use `get_last_lr()`.\", UserWarning)\n","/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py:1053: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n","  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1,  Train_Loss: 1.36, Train_Acc:41.58, Test_Loss:1.29, Test_Acc:45.10, eps: 2.49\n","Epoch: 2,  Train_Loss: 1.30, Train_Acc:43.13, Test_Loss:1.27, Test_Acc:49.02, eps: 3.04\n","Epoch: 3,  Train_Loss: 1.29, Train_Acc:41.62, Test_Loss:1.25, Test_Acc:50.98, eps: 3.49\n","Epoch: 4,  Train_Loss: 1.25, Train_Acc:54.07, Test_Loss:1.23, Test_Acc:54.90, eps: 3.88\n","Epoch: 5,  Train_Loss: 1.23, Train_Acc:48.97, Test_Loss:1.21, Test_Acc:60.78, eps: 4.24\n","Epoch: 6,  Train_Loss: 1.22, Train_Acc:51.28, Test_Loss:1.19, Test_Acc:66.67, eps: 4.56\n","Epoch: 7,  Train_Loss: 1.22, Train_Acc:51.69, Test_Loss:1.18, Test_Acc:68.63, eps: 4.87\n","Epoch: 8,  Train_Loss: 1.21, Train_Acc:48.11, Test_Loss:1.16, Test_Acc:64.71, eps: 5.16\n","Epoch: 9,  Train_Loss: 1.19, Train_Acc:53.93, Test_Loss:1.15, Test_Acc:64.71, eps: 5.44\n","Epoch: 10,  Train_Loss: 1.14, Train_Acc:59.11, Test_Loss:1.13, Test_Acc:64.71, eps: 5.70\n","Epoch: 11,  Train_Loss: 1.13, Train_Acc:59.41, Test_Loss:1.12, Test_Acc:64.71, eps: 5.96\n","Epoch: 12,  Train_Loss: 1.11, Train_Acc:61.69, Test_Loss:1.11, Test_Acc:64.71, eps: 6.20\n","Epoch: 13,  Train_Loss: 1.07, Train_Acc:62.23, Test_Loss:1.10, Test_Acc:64.71, eps: 6.44\n","Epoch: 14,  Train_Loss: 1.03, Train_Acc:65.99, Test_Loss:1.08, Test_Acc:66.67, eps: 6.67\n","Epoch: 15,  Train_Loss: 1.09, Train_Acc:65.08, Test_Loss:1.07, Test_Acc:66.67, eps: 6.90\n","Epoch: 16,  Train_Loss: 1.10, Train_Acc:63.00, Test_Loss:1.06, Test_Acc:66.67, eps: 7.12\n","Epoch: 17,  Train_Loss: 1.07, Train_Acc:63.18, Test_Loss:1.05, Test_Acc:66.67, eps: 7.34\n","Epoch: 18,  Train_Loss: 1.03, Train_Acc:64.47, Test_Loss:1.04, Test_Acc:68.63, eps: 7.55\n","Epoch: 19,  Train_Loss: 0.99, Train_Acc:67.38, Test_Loss:1.03, Test_Acc:68.63, eps: 7.75\n","Epoch: 20,  Train_Loss: 1.01, Train_Acc:66.83, Test_Loss:1.03, Test_Acc:68.63, eps: 7.95\n","Epoch: 21,  Train_Loss: 0.98, Train_Acc:69.37, Test_Loss:1.02, Test_Acc:68.63, eps: 8.15\n","Epoch: 22,  Train_Loss: 0.97, Train_Acc:67.23, Test_Loss:1.01, Test_Acc:68.63, eps: 8.35\n","Epoch: 23,  Train_Loss: 1.03, Train_Acc:58.42, Test_Loss:1.00, Test_Acc:68.63, eps: 8.54\n","Epoch: 24,  Train_Loss: 0.96, Train_Acc:69.12, Test_Loss:0.99, Test_Acc:70.59, eps: 8.73\n","Epoch: 25,  Train_Loss: 0.90, Train_Acc:68.72, Test_Loss:0.99, Test_Acc:70.59, eps: 8.91\n","Epoch: 26,  Train_Loss: 0.96, Train_Acc:70.37, Test_Loss:0.98, Test_Acc:70.59, eps: 9.10\n","Epoch: 27,  Train_Loss: 0.95, Train_Acc:68.23, Test_Loss:0.98, Test_Acc:72.55, eps: 9.28\n","Epoch: 28,  Train_Loss: 0.95, Train_Acc:66.34, Test_Loss:0.97, Test_Acc:72.55, eps: 9.46\n","Epoch: 29,  Train_Loss: 0.89, Train_Acc:71.23, Test_Loss:0.97, Test_Acc:72.55, eps: 9.63\n","Epoch: 30,  Train_Loss: 0.92, Train_Acc:70.90, Test_Loss:0.96, Test_Acc:72.55, eps: 9.81\n","Epoch: 31,  Train_Loss: 0.89, Train_Acc:70.41, Test_Loss:0.96, Test_Acc:72.55, eps: 9.98\n","Epoch: 32,  Train_Loss: 0.92, Train_Acc:68.04, Test_Loss:0.96, Test_Acc:72.55, eps: 10.15\n","Epoch: 33,  Train_Loss: 0.88, Train_Acc:71.50, Test_Loss:0.95, Test_Acc:72.55, eps: 10.31\n","Epoch: 34,  Train_Loss: 0.92, Train_Acc:68.91, Test_Loss:0.95, Test_Acc:72.55, eps: 10.48\n","Epoch: 35,  Train_Loss: 0.90, Train_Acc:69.57, Test_Loss:0.95, Test_Acc:72.55, eps: 10.65\n","Epoch: 36,  Train_Loss: 0.88, Train_Acc:73.02, Test_Loss:0.94, Test_Acc:72.55, eps: 10.81\n","Epoch: 37,  Train_Loss: 0.87, Train_Acc:73.46, Test_Loss:0.94, Test_Acc:72.55, eps: 10.97\n","Epoch: 38,  Train_Loss: 0.86, Train_Acc:69.91, Test_Loss:0.94, Test_Acc:72.55, eps: 11.13\n","Epoch: 39,  Train_Loss: 0.87, Train_Acc:70.04, Test_Loss:0.94, Test_Acc:72.55, eps: 11.29\n","Epoch: 40,  Train_Loss: 0.90, Train_Acc:68.72, Test_Loss:0.94, Test_Acc:72.55, eps: 11.45\n","Epoch: 41,  Train_Loss: 0.94, Train_Acc:70.00, Test_Loss:0.94, Test_Acc:72.55, eps: 11.61\n","Epoch: 42,  Train_Loss: 0.88, Train_Acc:72.68, Test_Loss:0.94, Test_Acc:72.55, eps: 11.76\n","Epoch: 43,  Train_Loss: 0.89, Train_Acc:74.35, Test_Loss:0.94, Test_Acc:72.55, eps: 11.91\n","Epoch: 44,  Train_Loss: 0.89, Train_Acc:68.37, Test_Loss:0.94, Test_Acc:72.55, eps: 12.06\n","Epoch: 45,  Train_Loss: 0.85, Train_Acc:71.21, Test_Loss:0.94, Test_Acc:72.55, eps: 12.21\n","Epoch: 46,  Train_Loss: 0.90, Train_Acc:70.24, Test_Loss:0.94, Test_Acc:72.55, eps: 12.36\n","Epoch: 47,  Train_Loss: 0.89, Train_Acc:64.41, Test_Loss:0.94, Test_Acc:72.55, eps: 12.52\n","Epoch: 48,  Train_Loss: 0.92, Train_Acc:65.43, Test_Loss:0.94, Test_Acc:72.55, eps: 12.66\n","Epoch: 49,  Train_Loss: 0.91, Train_Acc:67.77, Test_Loss:0.94, Test_Acc:72.55, eps: 12.80\n","Epoch: 50,  Train_Loss: 0.90, Train_Acc:65.66, Test_Loss:0.94, Test_Acc:72.55, eps: 12.95\n"]}],"source":["# define LR schedule\n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, float(epochs))\n","\n","# start training\n","for epoch in range(1, epochs + 1):\n","    model.train()\n","    scheduler.step()\n","    lr = scheduler.get_lr()[0]\n","    train_losses = []\n","    train_correct = 0.0\n","    train_total = 0.0\n","    for batch_idx, (data, target) in enumerate(trainloader):\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        train_losses.append(loss.item())\n","        # convert output probabilities to predicted class\n","        pred = output.data.max(1, keepdim=True)[1]\n","        # compare predictions to true label\n","        train_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n","        train_total += data.size(0)\n","    train_acc = 100. * train_correct / train_total\n","\n","    epsilon = privacy_engine.get_epsilon(delta)\n","\n","    model.eval()\n","    test_losses = []\n","    test_correct = 0.0\n","    test_total = 0.0\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(testloader):\n","            output = model(data)\n","            loss = criterion(output, target)\n","            test_losses.append(loss.item())\n","            # convert output probabilities to predicted class\n","            pred = output.data.max(1, keepdim=True)[1]\n","            # compare predictions to true label\n","            test_correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n","            test_total += data.size(0)\n","        test_acc = 100. * test_correct / test_total\n","\n","    print(\"Epoch: {0},  Train_Loss: {1:.2f}, Train_Acc:{2:.2f}, Test_Loss:{3:.2f}, Test_Acc:{4:.2f}, eps: {5:.2f}\".format(epoch, np.mean(train_losses), train_acc, np.mean(test_losses), test_acc, epsilon))"]},{"cell_type":"markdown","metadata":{"id":"uTLBUewC82sc"},"source":["# Practice Questions"]},{"cell_type":"markdown","metadata":{"id":"9BP292CBHHmN"},"source":["1. Try to modfiy ToyNN and fit again, see what will happen."]},{"cell_type":"markdown","metadata":{"id":"BJph1ryeHRZE"},"source":["2. Explore PrivacyEngine modules."]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}